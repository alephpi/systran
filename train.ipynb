{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209129472\n"
     ]
    }
   ],
   "source": [
    "from my_train import create_training_dataset, load_vocabulary\n",
    "from model import Transformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "\n",
    "args = argparse.Namespace()\n",
    "args.src_vocab = '../corpus/vocab_en_fr.txt'\n",
    "args.tgt_vocab = '../corpus/vocab_en_fr.txt'\n",
    "args.device = 'cpu'\n",
    "\n",
    "source_vocabulary, _ = load_vocabulary(args.src_vocab)\n",
    "target_vocabulary, target_vocabulary_rev = load_vocabulary(args.tgt_vocab)\n",
    "\n",
    "bos = target_vocabulary[\"<s>\"]\n",
    "eos = target_vocabulary[\"</s>\"]\n",
    "\n",
    "model = Transformer(\n",
    "    len(source_vocabulary),\n",
    "    len(target_vocabulary),\n",
    "    share_embeddings=True,\n",
    ")\n",
    "\n",
    "model.to(args.device)\n",
    "model.train()\n",
    "\n",
    "n = 0\n",
    "for param in model.parameters():\n",
    "    n += param.numel()\n",
    "print(n)\n",
    "\n",
    "source_path = './corpus/rep_test.en.tok'\n",
    "target_path = './corpus/rep_test.fr.tok'\n",
    "\n",
    "# source_path = '../corpus/train.en.tok'\n",
    "# target_path = '../corpus/train.fr.tok'\n",
    "\n",
    "batch_type = \"tokens\"\n",
    "# batch_type is the batch_size unit, for tokens we need to give larger one\n",
    "batch_size = 1200\n",
    "effective_batch_size = 2400\n",
    "\n",
    "label_smoothing = 0.1\n",
    "padding_idx = 0\n",
    "\n",
    "max_source_len = 150\n",
    "max_target_len = 150\n",
    "world_size = 1\n",
    "\n",
    "accum_steps = (\n",
    "    effective_batch_size // (batch_size * world_size)\n",
    "    if effective_batch_size is not None\n",
    "    else 1\n",
    ")\n",
    "\n",
    "dataset = create_training_dataset(\n",
    "    source_path,\n",
    "    target_path,\n",
    "    source_vocabulary,\n",
    "    target_vocabulary,\n",
    "    batch_size=batch_size,\n",
    "    batch_type=batch_type,\n",
    "    maximum_source_length=max_source_len,\n",
    "    maximum_target_length=max_target_len,\n",
    "    device=args.device,\n",
    "    num_accum_batches=accum_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-Jul-09 09:37:58.618000 UTC [dataset@SpawnProcess-1] INFO Shuffling 739 elements\n",
      "2023-Jul-09 09:37:58.660000 UTC [dataset@SpawnProcess-1] INFO Shuffling 739 elements\n"
     ]
    }
   ],
   "source": [
    "batches = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batches[0]\n",
    "s, ti, to = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 76])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(s, ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 77, 32000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1177e+01,  5.6754e+00,  2.0808e+01,  5.3710e+00,  5.8044e+00,\n",
       "         -1.6948e+01, -2.1228e+01, -1.1452e+01, -2.0809e+01, -1.5157e+01,\n",
       "         -4.9674e+01, -1.0409e+01, -1.6564e+01,  7.3628e+00, -1.3288e+01,\n",
       "         -4.0528e+01,  8.6779e+00, -1.5255e+00,  1.8660e+01, -1.9715e+01,\n",
       "         -5.1162e+01, -4.9488e+01, -1.7580e+00,  6.2387e+00, -8.0234e+00,\n",
       "         -7.8371e-01, -1.8518e+01, -1.3783e+01, -8.3405e+00, -5.0241e+00,\n",
       "         -4.7232e+00, -1.1336e+01, -4.4768e+01, -1.3607e+01, -4.1738e+01,\n",
       "         -3.3142e+01, -3.3414e+00, -2.8888e+01, -1.5144e+01, -2.0982e+01,\n",
       "         -4.5710e+01,  1.5156e+01, -1.8768e+01,  2.0997e+00, -2.0527e+01,\n",
       "          3.8572e+00, -5.5131e+01, -1.1827e+01, -2.0391e+00, -1.4929e+01,\n",
       "          3.3819e+00, -4.3766e+01, -3.7580e+01, -4.7864e+01, -2.6709e+01,\n",
       "         -2.5742e+01, -1.3922e+01, -4.9000e+01, -1.7419e+01, -4.2266e+01,\n",
       "         -9.4362e+00, -3.8519e+01, -9.0500e+00, -3.5786e+01, -4.9980e+00,\n",
       "         -4.3623e+01,  1.5637e+01, -2.6938e+01, -5.8004e+01, -4.3060e+01,\n",
       "         -3.2458e+01, -9.3584e+00, -5.2225e+01, -4.6196e+01, -4.5142e+01,\n",
       "         -4.1662e+01, -4.1487e+01],\n",
       "        [ 4.1406e+01,  4.7405e+01, -1.9174e+01, -7.1757e+00, -2.0241e+01,\n",
       "         -2.4238e+01, -3.1336e+01, -4.4361e+01,  4.1706e+00, -1.7886e+01,\n",
       "         -3.6390e+01, -3.1429e+01, -1.9486e+01,  6.8436e+00, -2.4177e+01,\n",
       "         -1.0203e+01,  2.0460e+01, -3.2367e+01,  3.1109e+00, -2.8089e+01,\n",
       "         -3.0632e+01, -4.3677e+01, -4.1740e+01, -1.0683e-01, -1.4395e+01,\n",
       "         -4.9547e+01,  5.9256e+00, -3.7628e+01, -8.2217e+00, -5.4690e+00,\n",
       "         -1.2829e+01, -9.8254e+00, -4.2461e+01, -1.3441e+01, -1.0189e+01,\n",
       "         -5.8547e+01, -3.6436e+01, -5.8125e+01, -3.9962e+01, -7.1322e+01,\n",
       "         -5.6393e+01, -4.4476e+01, -3.2979e+01, -3.4040e+01, -3.9727e+01,\n",
       "         -4.9553e+01, -3.6572e+01, -1.4077e+01,  2.8387e+00, -3.1401e+01,\n",
       "         -3.1687e+01, -3.7781e+01, -2.3068e+00, -1.5518e+01, -7.9577e+00,\n",
       "         -1.4855e+01,  7.0338e+00, -3.4583e+01, -5.3376e+01, -2.9910e+01,\n",
       "         -4.6687e+01, -1.5642e+01,  4.8793e+00, -3.5177e+01, -2.4907e+01,\n",
       "         -2.2213e+01, -1.2853e+00, -1.1066e+01, -6.6187e+01, -6.0934e+01,\n",
       "         -6.6489e+01, -7.5665e+01, -4.5758e+01, -5.0676e+01, -4.2801e+01,\n",
       "         -7.0347e+01, -5.7655e+01],\n",
       "        [-8.3444e+00,  1.2238e+01,  3.7383e+01,  2.9615e+01,  4.2606e+01,\n",
       "         -8.4058e+00, -3.7616e+01, -2.6952e+01,  2.1396e+01,  2.2897e+00,\n",
       "         -1.5490e+01,  7.3565e+00,  1.5035e+01, -5.0273e+01,  1.0483e+01,\n",
       "         -1.2454e+01,  2.5161e+00, -1.5141e+01, -8.9879e+00, -1.2035e+01,\n",
       "         -1.4660e+01, -1.1308e+01, -5.0098e+00, -3.3019e+00, -2.6079e+01,\n",
       "         -1.4324e+01, -1.8787e+01, -2.2758e+01, -1.2434e+01, -1.3188e+01,\n",
       "         -1.0479e+01, -2.0886e+01,  1.3751e+00, -4.1444e+00, -4.9610e+01,\n",
       "         -1.0499e+01, -2.9447e+01, -2.3646e+01, -2.1332e+01, -1.3077e+01,\n",
       "         -1.9596e+01, -4.5248e+00, -1.3790e+01, -7.5908e+00,  1.5333e+01,\n",
       "         -2.2322e+00, -2.3850e+01, -4.6026e+01, -2.1037e+01,  5.4641e+00,\n",
       "         -1.2026e+01, -3.5869e+00, -4.8792e+00, -8.8592e+00, -2.3510e+01,\n",
       "          1.4053e+00, -4.1246e+01, -3.7489e+01, -4.5805e+01, -1.1396e+01,\n",
       "         -2.9162e+01,  9.2053e+00,  8.4222e+00,  3.7207e-02,  2.2875e+01,\n",
       "         -1.9434e-01,  9.1552e+00,  1.7923e+00, -2.4453e+01, -2.9699e+01,\n",
       "         -1.6355e+01,  4.9172e+00, -2.0818e+01, -2.7051e+01, -1.7364e+01,\n",
       "         -6.8992e+01, -2.0298e+01],\n",
       "        [-8.1979e+00,  9.1219e+00,  7.7996e+00, -2.5299e+00, -3.1779e+01,\n",
       "          2.6005e+00, -8.7447e+00, -6.2916e+01, -3.1291e+01, -1.4178e+01,\n",
       "          6.2607e-01, -1.7414e+01, -2.6749e+01, -2.9093e+01, -3.1007e+01,\n",
       "         -3.0802e+01, -1.8337e+01, -8.7915e+00, -1.9286e+01, -2.1499e+01,\n",
       "          9.1086e+00, -1.0868e+01, -5.1794e+00, -1.5876e+01, -1.9343e+01,\n",
       "          8.2481e+00, -1.8538e+01, -4.2888e+01,  1.0338e+01, -1.3181e+00,\n",
       "         -4.2273e+01,  1.6646e+00,  1.0180e+01, -1.1180e+01, -4.0480e+01,\n",
       "         -3.6351e+01, -3.4482e+01, -3.1087e+01,  2.6567e-01, -8.1760e+00,\n",
       "         -2.5220e+01, -2.6707e+01, -7.4782e+00, -3.5693e+01, -2.6068e+01,\n",
       "         -1.2174e+01, -1.1544e+01, -1.7798e+01, -1.9929e+01, -2.9706e+01,\n",
       "          1.1219e+01, -1.5806e+00, -1.1637e+01, -1.5747e+01, -1.4792e+01,\n",
       "          8.6820e+00, -2.1079e+01, -1.6024e+01, -6.4627e+01, -3.3153e+01,\n",
       "         -4.4089e+01, -4.7624e+00, -2.2431e+01,  1.3529e+01,  1.0201e+01,\n",
       "         -4.4320e+01, -1.6968e+01, -1.6005e+01, -4.3774e+01, -1.3992e+01,\n",
       "         -3.7361e+01,  2.4030e+00, -2.0862e+01, -4.8309e+01, -3.0806e+01,\n",
       "         -3.5921e+01, -2.6811e+01],\n",
       "        [ 6.0314e+00, -3.5206e+01, -1.5295e+01,  2.1498e+01,  4.1317e+00,\n",
       "         -4.3561e+00, -4.8110e+01, -3.9855e+01, -2.1866e+01,  9.5478e-01,\n",
       "         -1.8829e+01, -2.7240e+01, -1.5686e+01, -1.1931e+01, -2.6522e+01,\n",
       "         -1.3399e+01, -3.9917e+01, -1.8207e+01, -2.0015e+01, -2.5544e+01,\n",
       "         -6.7478e+00, -4.6533e+01, -2.5152e+01, -3.1994e+01, -2.7539e-01,\n",
       "         -3.0854e+01, -4.8570e+01, -4.0457e+01, -4.2998e+01,  1.4984e+01,\n",
       "         -9.9952e+00, -3.8678e+01,  3.9430e+00, -1.7812e+01, -3.7928e+01,\n",
       "         -7.3485e+01, -2.2130e+01, -3.2486e+01, -3.0519e+01, -2.5143e+01,\n",
       "         -4.2814e+01, -2.0265e+01,  3.7436e-01,  1.2771e+01, -1.5496e+01,\n",
       "         -6.5954e+01, -8.7865e+00, -2.0691e+01,  4.1000e+00, -3.0276e+01,\n",
       "         -2.3642e+01, -1.7949e+01, -2.3950e+01, -1.2807e+01, -1.2427e+01,\n",
       "         -7.0107e+00, -6.9667e+01, -2.9905e+01, -4.1559e+01, -4.6944e+01,\n",
       "         -8.1553e+00, -3.3608e+01, -3.7620e+01, -3.6781e+00,  2.3874e+01,\n",
       "         -2.7075e+01, -4.8931e+00, -4.1386e+01, -4.3502e+01, -3.1142e+01,\n",
       "         -3.6528e+00, -1.4888e+01, -3.4856e+01, -3.4128e+01, -6.2153e+01,\n",
       "         -5.3181e+01, -2.7473e+01],\n",
       "        [ 1.0248e+01, -4.7805e+01,  1.3183e+01, -2.3837e+01, -2.7435e-01,\n",
       "         -2.3612e+00, -1.9681e+01,  2.4912e+01, -1.1311e+01, -3.5890e+01,\n",
       "          2.5108e+01, -1.4027e+01, -3.8697e+01, -4.6273e+01,  1.0526e+01,\n",
       "         -3.5557e+01,  1.5721e+01,  2.3217e+01, -1.5752e+01,  2.4665e+01,\n",
       "          6.8907e+00,  7.4286e+00,  3.6406e+00,  1.6507e+01,  1.9804e+01,\n",
       "         -2.8606e+01, -3.6803e+01,  5.4537e+00, -7.3401e+00, -2.7884e+01,\n",
       "          1.4240e+01,  1.1985e+01,  1.1793e+01, -9.6432e+00, -3.0559e+01,\n",
       "         -1.5365e+01, -4.0266e+00, -3.6738e+01, -1.1172e+01, -6.0315e+01,\n",
       "         -4.8489e+01, -2.8122e+01, -4.9237e+00, -3.6764e+01, -3.8250e+01,\n",
       "         -4.0986e+01, -3.4564e+01, -2.8664e+01, -2.4282e+01, -1.7856e+01,\n",
       "         -1.3277e+01,  1.1300e+01, -2.0909e+01, -4.8455e+01,  1.0022e+01,\n",
       "          2.8215e+00, -3.6775e+01, -2.6785e+01, -3.2933e+01, -4.7822e+01,\n",
       "          2.3381e+01,  1.4705e+00, -4.2554e+01,  3.0609e+00, -1.7555e+01,\n",
       "         -2.2498e+01, -3.7982e+01, -3.3581e+01, -2.0001e+01, -2.7165e+01,\n",
       "         -2.1604e+01, -6.2748e+01, -2.2699e+01, -1.5507e+01, -6.1048e+01,\n",
       "         -5.6310e+01, -1.2231e+01],\n",
       "        [ 2.9202e+01, -7.5296e+00,  4.2769e+00, -1.5095e+01, -1.4473e+01,\n",
       "          1.4275e+01, -4.6277e+01, -1.2088e+01, -5.4935e+01, -1.2430e+01,\n",
       "         -4.6892e+01, -1.8211e+01, -3.9071e+01,  1.0213e+01,  2.1653e+01,\n",
       "         -1.4508e+01, -2.7275e+01, -1.2675e+01, -1.6781e+01, -2.5407e+01,\n",
       "         -4.2543e+01, -3.1239e+01, -5.5915e-01, -5.0543e+01, -4.6458e+01,\n",
       "         -2.6887e+01,  3.5410e+00, -3.6672e+01, -5.8113e+00, -6.5774e+01,\n",
       "         -8.4541e+00, -1.6135e+00,  3.0645e+00, -2.6250e+01, -2.4577e+01,\n",
       "         -2.5157e+01, -4.7286e+01, -2.5284e+01,  3.2207e+00, -5.6536e+01,\n",
       "         -4.2835e+01, -2.8895e+01, -2.0720e+00, -1.8680e+01, -3.3660e+01,\n",
       "         -4.9963e+01, -6.1599e+01, -6.9124e+01, -4.5889e+01, -2.1921e+01,\n",
       "         -2.8865e+01, -3.7214e+01, -2.2163e+01, -2.3365e+01, -2.2720e+01,\n",
       "         -2.6318e-01, -3.0329e+01, -2.9518e+01, -9.5128e+00, -3.5204e+01,\n",
       "         -6.1944e+01, -4.8976e+00, -1.6460e+01,  2.0444e+01, -6.5686e+00,\n",
       "         -2.0533e+01, -3.4790e+01, -2.3391e+01, -2.4440e+01, -5.4841e+01,\n",
       "         -1.6329e+01, -4.5504e+01, -4.6868e+01, -6.4806e+01, -4.3284e+01,\n",
       "         -8.4224e+01, -5.2011e+01],\n",
       "        [-1.5060e+01, -1.7922e+01, -3.8757e+01, -4.1453e+01, -2.1341e+01,\n",
       "         -5.2671e+01, -3.1992e+01, -4.2101e+01, -4.6551e+01, -5.1902e+01,\n",
       "         -3.3382e+01, -3.4280e+00,  3.7276e+00, -5.5724e+00,  1.8086e+01,\n",
       "         -3.5541e+00,  8.5452e+00, -3.4606e+01, -8.4978e+00, -3.0656e+00,\n",
       "         -2.0642e+01, -5.1546e+00,  2.2011e+01, -9.2591e-01, -6.7903e+00,\n",
       "         -2.8641e+01, -9.6461e+00, -2.5811e+01, -2.2665e+01, -3.0048e+01,\n",
       "         -3.9588e+01, -2.5894e+01, -1.4457e+01, -3.3996e+01, -3.8389e+01,\n",
       "         -2.9667e+01, -2.5382e+01, -4.5550e+01, -3.8557e+01, -3.0804e+01,\n",
       "         -2.4132e+01,  1.5539e+01,  1.5337e+00, -2.3883e+00, -1.9669e+01,\n",
       "         -2.5282e+01, -2.5509e+01, -3.0830e+01, -2.2122e+01, -6.3197e+00,\n",
       "         -1.2443e+01, -2.4594e+01, -2.8411e+00, -4.9331e+01, -3.8711e+01,\n",
       "         -1.7868e+01, -1.0137e+01, -1.6142e+01, -2.6667e+01, -5.8565e+01,\n",
       "         -3.5594e+01, -5.5146e+01, -1.2457e+01,  2.2213e-01, -1.5375e+01,\n",
       "          1.5174e+01, -2.3072e+01, -3.1556e+00, -4.7935e+01, -3.9197e+01,\n",
       "         -2.4621e+01, -1.9152e+01, -4.8470e+01, -9.8216e+00, -5.5606e+01,\n",
       "         -6.0902e+01, -6.2394e+01]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6404.0410, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit -n 100\n",
    "l = F.cross_entropy(\n",
    "    input=logits.view(-1, logits.shape[-1]),\n",
    "    target=to.view(-1),\n",
    "    reduction='sum',\n",
    "    # weight=weight,\n",
    "    label_smoothing=label_smoothing\n",
    ")\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 77, 32000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_mask = torch.load('./penalty_mask.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5578)\n",
      "tensor(4.5578)\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([[0.1, 0.2, 0.3], [0.2, 0.1, 0.3], [0.2, 0.1, 0.3]])\n",
    "target = torch.tensor([[2*0.8, 0.1, 0.1], [2*0.1, 0.8, 0.1], [\n",
    "                      2*0.1, 0.1, 0.8]], dtype=torch.float32)\n",
    "target2 = torch.tensor([0, 1, 2])\n",
    "print(F.cross_entropy(input, target, reduction='sum'))\n",
    "# print(F.cross_entropy(input, target2, label_smoothing=0.2))\n",
    "print(F.cross_entropy(input, target2, reduction='sum', label_smoothing=0.3,\n",
    "      weight=torch.tensor([2, 1, 1], dtype=torch.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_train import ce_loss_with_rep_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 s ± 7.69 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "ce_loss_with_rep_penalty(logits, to, penalty_mask, 0.1, 0.1, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 77, 32000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 57, 32000]), torch.Size([16, 57]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, to.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.3 ms ± 490 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "F.cross_entropy(logits.view(-1, 32000), to.view(-1),\n",
    "                label_smoothing=0.1, reduction='sum')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
